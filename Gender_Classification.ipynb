{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries"
      ],
      "metadata": {
        "id": "hucRc2B0zDSn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bPGAjHs5y4wq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from keras.preprocessing.image import ImageDataGenerator as data_augment\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, Dropout, Flatten, Dense, GlobalAveragePooling2D, BatchNormalization\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Importation\n"
      ],
      "metadata": {
        "id": "mGwc3LT5zVDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Uncomment below to clone the dataset from github\n",
        "\n",
        "!git clone https://github.com/echefulouis/Gender-Classification-Model.git\n"
      ],
      "metadata": {
        "id": "mfy_rXGRzcuc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a235c6cb-2648-498c-bc2e-6af7376586cd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Gender-Classification-Model'...\n",
            "remote: Enumerating objects: 58653, done.\u001b[K\n",
            "remote: Total 58653 (delta 0), reused 0 (delta 0), pack-reused 58653\u001b[K\n",
            "Receiving objects: 100% (58653/58653), 261.43 MiB | 16.00 MiB/s, done.\n",
            "Updating files: 100% (58659/58659), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing and Augmentation"
      ],
      "metadata": {
        "id": "FYieb-O3DoYd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_generate_training = data_augment (rescale=1./255,  #This parameter rescales the pixel values of the image to a value between 0 and 1\n",
        "                              shear_range = 0.2,        #This parameter randomly applies a shear transformation to the image, which skews the image \n",
        "                                                        #in a particular direction.\n",
        "                              zoom_range = 0.2,\n",
        "                              fill_mode = \"nearest\",\n",
        "                              horizontal_flip = True,\n",
        "                              width_shift_range = 0.2,\n",
        "                              height_shift_range = 0.2,\n",
        "                              \n",
        "                              validation_split = 0.15)  #This parameter splits the training data into a training set and a validation set, \n",
        "                                                        #with 15% of the data being used for validation.\n",
        "\n",
        "data_generate_test = data_augment(rescale = 1./255)     #This parameter rescales the pixel values of the image to a value between 0 and 1"
      ],
      "metadata": {
        "id": "TaUR0teszKlv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = data_generate_training.flow_from_directory(\"/content/Gender-Classification-Model/GC dataset/Training\",\n",
        "                                          target_size = (96, 96),\n",
        "                                          seed = 123,\n",
        "                                          batch_size = 32,\n",
        "                                          subset = \"training\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNaDZffpBSDf",
        "outputId": "ba253cce-2500-4462-80b6-e54a126602de"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 39959 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "test_data = data_generate_training.flow_from_directory(\"/content/Gender-Classification-Model/GC dataset/Validation\",\n",
        "                                          target_size = (96, 96),\n",
        "                                          seed = 123,\n",
        "                                          batch_size = 32,\n",
        "                                          subset = \"validation\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Auh7ohmw-T1E",
        "outputId": "f58510ed-d109-4f9d-ec11-5790ec96810b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1747 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Creation and Training "
      ],
      "metadata": {
        "id": "FjXJeGEk_due"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CNNmodel = keras.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), input_shape=(96, 96, 3), activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Dropout(0.2),\n",
        "    \n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Dropout(0.2),\n",
        "    \n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Dropout(0.2),\n",
        "    \n",
        "    layers.Flatten(),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dropout(0.2),  \n",
        "    layers.Dense(128, activation = 'relu'),\n",
        "    layers.Dense(2, activation = 'sigmoid')\n",
        "])\n"
      ],
      "metadata": {
        "id": "x4J_k9ku_X93"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "CNNmodel.compile(optimizer='adam',\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = CNNmodel.fit(train_data, epochs = 10, validation_data = test_data) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVanrji2_sAl",
        "outputId": "8f1c192b-9a47-4be1-979b-b09d28c61b93"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1249/1249 [==============================] - 151s 111ms/step - loss: 0.4411 - accuracy: 0.8138 - val_loss: 0.3650 - val_accuracy: 0.8357\n",
            "Epoch 2/10\n",
            "1249/1249 [==============================] - 139s 111ms/step - loss: 0.2278 - accuracy: 0.9104 - val_loss: 0.3570 - val_accuracy: 0.8357\n",
            "Epoch 3/10\n",
            "1249/1249 [==============================] - 139s 111ms/step - loss: 0.1933 - accuracy: 0.9273 - val_loss: 0.3054 - val_accuracy: 0.8809\n",
            "Epoch 4/10\n",
            "1249/1249 [==============================] - 136s 109ms/step - loss: 0.1751 - accuracy: 0.9352 - val_loss: 0.1481 - val_accuracy: 0.9450\n",
            "Epoch 5/10\n",
            "1249/1249 [==============================] - 134s 107ms/step - loss: 0.1633 - accuracy: 0.9397 - val_loss: 0.2138 - val_accuracy: 0.9296\n",
            "Epoch 6/10\n",
            "1249/1249 [==============================] - 132s 106ms/step - loss: 0.1551 - accuracy: 0.9443 - val_loss: 0.1639 - val_accuracy: 0.9359\n",
            "Epoch 7/10\n",
            "1249/1249 [==============================] - 134s 107ms/step - loss: 0.1485 - accuracy: 0.9455 - val_loss: 0.1641 - val_accuracy: 0.9382\n",
            "Epoch 8/10\n",
            "1249/1249 [==============================] - 134s 107ms/step - loss: 0.1462 - accuracy: 0.9475 - val_loss: 0.1301 - val_accuracy: 0.9565\n",
            "Epoch 9/10\n",
            "1249/1249 [==============================] - 132s 106ms/step - loss: 0.1387 - accuracy: 0.9507 - val_loss: 0.2699 - val_accuracy: 0.8729\n",
            "Epoch 10/10\n",
            "1249/1249 [==============================] - 133s 107ms/step - loss: 0.1396 - accuracy: 0.9504 - val_loss: 0.1400 - val_accuracy: 0.9473\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VU_cWDJM_0kt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the validation dataset\n",
        "validation_accuracy = CNNmodel.evaluate(test_data)[1]\n",
        "\n",
        "print(\"Validation accuracy: {:.2f}%\".format(validation_accuracy * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Eu-RCLacyIF",
        "outputId": "86e9f24e-5543-4da5-90bc-c5ad18c9a298"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "55/55 [==============================] - 5s 87ms/step - loss: 0.1352 - accuracy: 0.9536\n",
            "Validation accuracy: 95.36%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Transfer Learning "
      ],
      "metadata": {
        "id": "jRh3MrnUBG7H"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8q3OVqRdBGI5"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}