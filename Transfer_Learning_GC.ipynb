{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "sWZdqirUlCDY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8LBGqiw5bcKL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from keras.preprocessing.image import ImageDataGenerator as data_augment\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, Dropout, Flatten, Dense, GlobalAveragePooling2D, BatchNormalization\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Importation"
      ],
      "metadata": {
        "id": "OUaXCvyAlBod"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Uncomment below to clone the dataset from github\n",
        "\n",
        "!git clone https://github.com/echefulouis/Gender-Classification-Model.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVcCrt_3bjdI",
        "outputId": "3fdb7cce-e10c-44b8-f834-e9c12290201d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Gender-Classification-Model'...\n",
            "remote: Enumerating objects: 58653, done.\u001b[K\n",
            "remote: Total 58653 (delta 0), reused 0 (delta 0), pack-reused 58653\u001b[K\n",
            "Receiving objects: 100% (58653/58653), 261.43 MiB | 15.82 MiB/s, done.\n",
            "Updating files: 100% (58659/58659), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Preprocessing and Augmentation"
      ],
      "metadata": {
        "id": "HGj6lwCHlKku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "train_generator = train_datagen.flow_from_directory('/content/Gender-Classification-Model/GC dataset/Training', target_size=(224, 224), batch_size=32)\n",
        "\n",
        "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "val_generator = val_datagen.flow_from_directory('/content/Gender-Classification-Model/GC dataset/Validation', target_size=(224, 224), batch_size=32)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7E6UXIUZbka4",
        "outputId": "47d1b280-c6c5-4e9f-9869-f2f01b784fa2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 47009 images belonging to 2 classes.\n",
            "Found 11649 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the pre-trained MobileNetV2 model"
      ],
      "metadata": {
        "id": "tn7OtFbPlUOS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained MobileNetV2 model\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n"
      ],
      "metadata": {
        "id": "PaDWPtnBbvMR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9303d4c3-93a2-440f-bf8b-6f0f7e5f82be"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9406464/9406464 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a custom classification layer\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "predictions = Dense(2, activation='softmax')(x)"
      ],
      "metadata": {
        "id": "lhOme6Flb0if"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "aKh6sDQLb8Qn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training "
      ],
      "metadata": {
        "id": "rJD0YaERlW0q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(train_generator, steps_per_epoch=train_generator.samples//train_generator.batch_size, epochs=10, validation_data=val_generator, validation_steps=val_generator.samples//val_generator.batch_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UK0HSZWqcBbX",
        "outputId": "2541a027-0876-4140-90e2-722cba965785"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1469/1469 [==============================] - 248s 145ms/step - loss: 0.1391 - accuracy: 0.9510 - val_loss: 2.1099 - val_accuracy: 0.5883\n",
            "Epoch 2/10\n",
            "1469/1469 [==============================] - 213s 145ms/step - loss: 0.1016 - accuracy: 0.9648 - val_loss: 0.6944 - val_accuracy: 0.8706\n",
            "Epoch 3/10\n",
            "1469/1469 [==============================] - 214s 145ms/step - loss: 0.0902 - accuracy: 0.9683 - val_loss: 1.0179 - val_accuracy: 0.8040\n",
            "Epoch 4/10\n",
            "1469/1469 [==============================] - 212s 144ms/step - loss: 0.0833 - accuracy: 0.9704 - val_loss: 3.7560 - val_accuracy: 0.5901\n",
            "Epoch 5/10\n",
            "1469/1469 [==============================] - 233s 158ms/step - loss: 0.0777 - accuracy: 0.9717 - val_loss: 0.1990 - val_accuracy: 0.9560\n",
            "Epoch 6/10\n",
            "1469/1469 [==============================] - 213s 145ms/step - loss: 0.0704 - accuracy: 0.9751 - val_loss: 0.1687 - val_accuracy: 0.9649\n",
            "Epoch 7/10\n",
            "1469/1469 [==============================] - 214s 145ms/step - loss: 0.0662 - accuracy: 0.9759 - val_loss: 2.1647 - val_accuracy: 0.7623\n",
            "Epoch 8/10\n",
            "1469/1469 [==============================] - 211s 144ms/step - loss: 0.0592 - accuracy: 0.9779 - val_loss: 0.3408 - val_accuracy: 0.9456\n",
            "Epoch 9/10\n",
            "1469/1469 [==============================] - 211s 143ms/step - loss: 0.0498 - accuracy: 0.9813 - val_loss: 0.1236 - val_accuracy: 0.9657\n",
            "Epoch 10/10\n",
            "1469/1469 [==============================] - 211s 143ms/step - loss: 0.0433 - accuracy: 0.9844 - val_loss: 0.1704 - val_accuracy: 0.9605\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation"
      ],
      "metadata": {
        "id": "nkOcIc0xlZft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "model.evaluate(val_generator, steps=val_generator.samples//val_generator.batch_size)"
      ],
      "metadata": {
        "id": "bB3OKvEmcDj2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f74935f-2008-4f09-fa3a-27d012269aa9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "364/364 [==============================] - 21s 58ms/step - loss: 0.1704 - accuracy: 0.9605\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.17036589980125427, 0.9605082273483276]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the validation dataset\n",
        "validation_accuracy = model.evaluate(val_generator, steps=val_generator.samples//val_generator.batch_size)[1]\n",
        "\n",
        "print(\"Validation accuracy: {:.2f}%\".format(validation_accuracy * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CuiFykI3Smr",
        "outputId": "74b3ce62-343e-4ecd-c86d-1bc93573c804"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "364/364 [==============================] - 20s 56ms/step - loss: 0.1704 - accuracy: 0.9605\n",
            "Validation accuracy: 96.05%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZoDI35v-3WxN"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}